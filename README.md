# Object_Detection_Using_Faster_R-CNN

This repository contains the implementation of an object detection system using Faster R-CNN with a ResNet50 FPN backbone in PyTorch. The project demonstrates how to use pre-trained models for detecting objects in images, evaluating detection accuracy, and visualizing results.

It uses the Faster R-CNN architecture, which is a two-stage detector that first proposes regions of interest and then classifies them. Key components include:

- **Transfer learning with a pre-trained ResNet50 FPN model**

- **Object detection with bounding box visualization**

- **Evaluation metrics including IoU (Intersection over Union)**

- **Support for the COCO dataset classes (80 categories)**

The system can detect various objects including people, vehicles, furniture, and household items with high accuracy when given appropriate input images.

## Features

- **Pre-trained Model**: Utilizes Faster R-CNN with ResNet50 FPN backbone pre-trained on COCO dataset

- **Object Detection**: Identifies objects in images with confidence scores

- **Visualization**: Draws bounding boxes around detected objects with labels and confidence scores

- **Evaluation**: Calculates detection accuracy using IoU metrics

- **Customizable Thresholds**: Adjustable confidence and IoU thresholds for different use cases

## Project Structure

```
Object-Detection-using-Faster-R-CNN/
│
├── train.py                 # Script to load and save the pre-trained Faster R-CNN model weights
├── detect.py                # Script for running object detection on images and visualizing results
├── evaluate.py              # Script for evaluating detection accuracy using IoU and other metrics
│
├── object_detection_model.pth   # Saved model weights (generated by train.py)
│
├── images/
│   └── test/
│       ├── Home.jpg         # Sample test image of a house entrance with plants
│       └── Persons.jpeg      # Sample test image with multiple people
│
└── README.md                # Project documentation (this file)
```

## Requirements

- Python 3.6+

- PyTorch 1.7+

- torchvision

- OpenCV (cv2)

- NumPy

- Matplotlib

- PIL (Python Imaging Library)

## Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/object-detection-faster-rcnn.git
   cd object-detection-faster-rcnn
   ```
   
2. Install the required dependencies:
   ```bash
   pip install torch torchvision opencv-python numpy matplotlib pillow
   ```
3. Generate the model file:
   ```bash
   python train.py
   ```
   
This will create object_detection_model.pth by saving the pre-trained Faster R-CNN model.

## Usage

### Object Detection

To detect objects in your own images:

1. Add your images to a directory

2. Modify the image paths in detect.py:
   ```bash
   image_paths = [
       "path/to/your/image1.jpg",
       "path/to/your/image2.jpg"
   ]
   ```
3. Run the detection script:
   ```bash
   python detect.py
   ```
   
### Evaluation

To evaluate the model on test images:

1. Modify the test images and annotations in evaluate.py as needed

2. Run the evaluation script:
   ```bash
   python evaluate.py
   ```

## How It Works

### Model Architecture

The project uses Faster R-CNN with ResNet50 FPN backbone, which consists of:

1. **Backbone Network**: ResNet50 with Feature Pyramid Network (FPN) extracts features from input images

2. **Region Proposal Network (RPN)**: Proposes regions that might contain objects

3. **ROI (Region of Interest) Head**: Classifies and refines bounding boxes for detected objects

### Detection Process

1. Load the pre-trained model from object_detection_model.pth

2. Process input images using PyTorch's transformation pipeline

3. Pass transformed images through the model to get predictions

4. Filter predictions based on confidence threshold

5. Draw bounding boxes around detected objects with labels and confidence scores

6. Display or save the results

### Evaluation Metrics

The evaluation uses IoU (Intersection over Union) to measure detection accuracy:

- IoU calculates the overlap between predicted and ground truth bounding boxes

- Predictions with IoU above the threshold (default 0.5) are considered correct

- Accuracy is calculated as the ratio of correct detections to total ground truth objects

## Customization

### Adjusting Detection Threshold

You can adjust the confidence threshold for detections:
```bash
# Higher threshold for more confident detections
detect_objects_in_image("path/to/image.jpg", threshold=0.8)
# Lower threshold to detect more objects (may include false positives)
detect_objects_in_image("path/to/image.jpg", threshold=0.3)
```

### Filtering Specific Objects

You can modify the code to detect only specific object classes by filtering the COCO_INSTANCE_CATEGORY_NAMES list.

## Future Work

Potential improvements for this project:

- Implementing custom training on domain-specific datasets

- Adding real-time object detection with webcam support

- Exploring other model architectures like YOLO or SSD

- Implementing instance segmentation in addition to object detection

## Acknowledgments

This project builds upon several key technologies and research:

- Faster R-CNN architecture

- PyTorch and torchvision libraries

- ResNet50 architecture

- COCO dataset

## License
MIT License
